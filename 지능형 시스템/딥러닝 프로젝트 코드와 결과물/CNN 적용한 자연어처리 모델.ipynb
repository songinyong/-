{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리들 불러옴\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mastering QuickBooks 2020</td>\n",
       "      <td>Business&amp;Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-On Microsoft Teams</td>\n",
       "      <td>Business&amp;Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft 365 and SharePoint Online Cookb</td>\n",
       "      <td>Business&amp;Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft Power Platform Enterprise Architecture</td>\n",
       "      <td>Business&amp;Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odoo 12 Development Cookbook - Third Edition</td>\n",
       "      <td>Business&amp;Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title           theme\n",
       "0                         Mastering QuickBooks 2020  Business&Other\n",
       "1                          Hands-On Microsoft Teams  Business&Other\n",
       "2         Microsoft 365 and SharePoint Online Cookb  Business&Other\n",
       "3  Microsoft Power Platform Enterprise Architecture  Business&Other\n",
       "4      Odoo 12 Development Cookbook - Third Edition  Business&Other"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adata = pd.read_csv('데이터_최종.csv')\n",
    "# 데이터의 NAN값 제거\n",
    "Adata2 = Adata.dropna(axis=0)\n",
    "\n",
    "#일부 크롤링한 데이터중 \\nBook 같은 잘못된 데이터가 들어 있어 제거\n",
    "Adata2['title']= Adata2['title'].str.rstrip('\\nBook')\n",
    "\n",
    "\n",
    "Adata2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "지난 프로젝트와의 비교를 위해 생성한 토큰 생성기\n",
    "\"\"\"\n",
    "# 트위터나 페이스북 같은 SNS 텍스트를 분석할때 사용하는 토큰함수\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#tokenizer = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "#tokens = tokenizer.fit(Adata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "vect = CountVectorizer(tokenizer=casual_tokenize,min_df=3, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tokens = vect.fit(Adata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '! (',\n",
       " '! )',\n",
       " '! ...',\n",
       " '! :',\n",
       " '! all',\n",
       " '! book',\n",
       " '! for',\n",
       " '! with',\n",
       " '\"',\n",
       " '\" (',\n",
       " '\" )',\n",
       " '\" 6x9',\n",
       " '\" auth',\n",
       " '\" inches',\n",
       " '\" x',\n",
       " '\" x8',\n",
       " '#',\n",
       " '# (',\n",
       " '# )',\n",
       " '# ,',\n",
       " '# .',\n",
       " '# 1',\n",
       " '# 2005',\n",
       " '# 2008',\n",
       " '# 2010',\n",
       " '# 2012',\n",
       " '# 3.0',\n",
       " '# 4.0',\n",
       " '# 5.0',\n",
       " '# 6',\n",
       " '# 6.0',\n",
       " '# 7',\n",
       " '# 7.0',\n",
       " '# 7.1',\n",
       " '# 8',\n",
       " '# 8.0',\n",
       " '# :',\n",
       " '# and',\n",
       " '# book',\n",
       " '# by',\n",
       " '# challenge',\n",
       " '# cookbook',\n",
       " '# data',\n",
       " '# database',\n",
       " '# developers',\n",
       " '# for',\n",
       " '# functional',\n",
       " '# in',\n",
       " '# language',\n",
       " '# machine',\n",
       " '# multithreaded',\n",
       " '# programmer',\n",
       " '# programming',\n",
       " '# skills',\n",
       " '# step',\n",
       " '# with',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '& 10',\n",
       " '& 11',\n",
       " '& 17',\n",
       " '& 1z0',\n",
       " '& 2',\n",
       " '& 20',\n",
       " '& 2016',\n",
       " '& 220-1002',\n",
       " '& 220-702',\n",
       " '& 220-802',\n",
       " '& 220-902',\n",
       " '& a',\n",
       " '& a30',\n",
       " '& access',\n",
       " '& accounting',\n",
       " '& administration',\n",
       " '& alexa',\n",
       " '& algorithms',\n",
       " '& analytics',\n",
       " '& answers',\n",
       " '& applications',\n",
       " '& ass',\n",
       " '& assurance',\n",
       " '& bartlett',\n",
       " '& beyond',\n",
       " '& big',\n",
       " '& black',\n",
       " '& computer',\n",
       " '& computer-vision',\n",
       " '& css',\n",
       " '& data',\n",
       " '& delicious',\n",
       " '& detailed',\n",
       " '& development',\n",
       " '& dirty',\n",
       " '& document',\n",
       " '& easy',\n",
       " '& ex300',\n",
       " '& examples',\n",
       " '& excel',\n",
       " '& features',\n",
       " '& forms',\n",
       " '& fresh',\n",
       " '& hall',\n",
       " '& how',\n",
       " '& html',\n",
       " '& ii',\n",
       " '& internet',\n",
       " '& introduction',\n",
       " '& ipad',\n",
       " '& ipados',\n",
       " '& javascript',\n",
       " '& macos',\n",
       " '& maintaining',\n",
       " '& malware',\n",
       " '& management',\n",
       " '& microsoft',\n",
       " '& more',\n",
       " '& mysql',\n",
       " '& naimi',\n",
       " '& nosql',\n",
       " '& note',\n",
       " '& notebook',\n",
       " '& numbers',\n",
       " '& office',\n",
       " '& organised',\n",
       " '& password',\n",
       " '& pattern',\n",
       " '& personal',\n",
       " '& power',\n",
       " '& powerpoint',\n",
       " '& practices',\n",
       " '& reference',\n",
       " '& repairing',\n",
       " '& running',\n",
       " '& seniors',\n",
       " '& shortcuts',\n",
       " '& simple',\n",
       " '& smart',\n",
       " '& software',\n",
       " '& solutions',\n",
       " '& sql',\n",
       " '& techniques',\n",
       " '& tensorflow',\n",
       " '& the',\n",
       " '& tips',\n",
       " '& tools',\n",
       " '& tricks',\n",
       " '& troubleshooting',\n",
       " '& tuning',\n",
       " '& typesetting',\n",
       " '& unlock',\n",
       " '& w',\n",
       " '& white',\n",
       " '& word',\n",
       " '& xml',\n",
       " \"'\",\n",
       " \"' 99\",\n",
       " \"' certficiation\",\n",
       " \"' certification\",\n",
       " \"' comptia\",\n",
       " \"' guide\",\n",
       " \"' love\",\n",
       " \"' toolkit\",\n",
       " '(',\n",
       " '( (',\n",
       " '( 1',\n",
       " '( 10th',\n",
       " '( 110',\n",
       " '( 1146',\n",
       " '( 11th',\n",
       " '( 12.5',\n",
       " '( 18',\n",
       " '( 2',\n",
       " '( 20',\n",
       " '( 2015',\n",
       " '( 2017',\n",
       " '( 2018',\n",
       " '( 2019',\n",
       " '( 2020',\n",
       " '( 2nd',\n",
       " '( 3',\n",
       " '( 3d',\n",
       " '( 3rd',\n",
       " '( 4',\n",
       " '( 48',\n",
       " '( 4th',\n",
       " '( 5',\n",
       " '( 5th',\n",
       " '( 6',\n",
       " '( 61',\n",
       " '( 6th',\n",
       " '( 7',\n",
       " '( 7th',\n",
       " '( 9th',\n",
       " '( a',\n",
       " '( aca',\n",
       " '( acm',\n",
       " '( activate',\n",
       " '( adaptive',\n",
       " '( addison-wesley',\n",
       " '( adobe',\n",
       " '( advanced',\n",
       " '( advances',\n",
       " '( alexa',\n",
       " '( all-in-one',\n",
       " '( alphabetized',\n",
       " '( amazon',\n",
       " '( and',\n",
       " '( animal',\n",
       " '( apple',\n",
       " '( applications',\n",
       " '( applied',\n",
       " '( as',\n",
       " '( autocad',\n",
       " '( available',\n",
       " '( aws',\n",
       " '( b',\n",
       " '( beginners',\n",
       " '( benchmark',\n",
       " '( benjamin',\n",
       " '( bk',\n",
       " '( black',\n",
       " '( book',\n",
       " '( books',\n",
       " '( business',\n",
       " '( c',\n",
       " '( cambridge',\n",
       " '( ceh',\n",
       " '( certification',\n",
       " '( chapman',\n",
       " '( charles',\n",
       " '( cheat',\n",
       " '( clf-c',\n",
       " '( cls.education',\n",
       " '( code',\n",
       " '( coding',\n",
       " '( college',\n",
       " '( color',\n",
       " '( colored',\n",
       " '( communications',\n",
       " '( complete',\n",
       " '( computational',\n",
       " '( computer',\n",
       " '( computers',\n",
       " '( computing',\n",
       " '( control',\n",
       " '( cookbooks',\n",
       " '( core',\n",
       " '( covers',\n",
       " '( crash',\n",
       " '( csia',\n",
       " '( cuz',\n",
       " '( data',\n",
       " '( data-centric',\n",
       " '( definitive',\n",
       " '( deitel',\n",
       " '( developer',\n",
       " \"( developer's\",\n",
       " '( digital',\n",
       " '( discreet',\n",
       " '( discrete',\n",
       " '( dover',\n",
       " '( dv-mps',\n",
       " '( easy',\n",
       " '( echo',\n",
       " '( effective',\n",
       " '( electrical',\n",
       " '( embedded',\n",
       " '( english',\n",
       " '( essential',\n",
       " '( exam',\n",
       " '( exams',\n",
       " '( excel',\n",
       " \"( expert's\",\n",
       " '( exploring',\n",
       " '( first',\n",
       " '( for',\n",
       " '( french',\n",
       " '( frontiers',\n",
       " '( ft',\n",
       " '( ftd',\n",
       " '( game',\n",
       " '( gdp',\n",
       " '( german',\n",
       " '( go',\n",
       " '( graduate',\n",
       " '( hacking',\n",
       " '( hardcover',\n",
       " '( hbr',\n",
       " '( hidden',\n",
       " '( history',\n",
       " '( how',\n",
       " '( ibm',\n",
       " '( idc',\n",
       " '( illustrated',\n",
       " '( imperial',\n",
       " '( in',\n",
       " '( includes',\n",
       " '( information',\n",
       " '( instructions',\n",
       " '( instructor',\n",
       " '( intelligent',\n",
       " '( interactive',\n",
       " '( internal',\n",
       " '( international',\n",
       " '( internet',\n",
       " '( introduction',\n",
       " '( iot',\n",
       " '( isc',\n",
       " '( it',\n",
       " '( italian',\n",
       " '( itcc',\n",
       " '( j',\n",
       " '( java',\n",
       " '( job',\n",
       " '( jones',\n",
       " '( large',\n",
       " '( learn',\n",
       " '( learning',\n",
       " '( lecture',\n",
       " '( libro',\n",
       " '( machine',\n",
       " '( macmillan',\n",
       " '( make',\n",
       " '( management',\n",
       " '( mastering',\n",
       " '( mathematics',\n",
       " '( mcgraw-hill',\n",
       " '( mcsd',\n",
       " '( mcts',\n",
       " '( microsoft',\n",
       " '( mike',\n",
       " '( mindtap',\n",
       " '( missing',\n",
       " '( mit',\n",
       " '( mixed',\n",
       " '( monographs',\n",
       " '( morgan',\n",
       " '( mos',\n",
       " '( mr',\n",
       " '( mrexcel',\n",
       " '( murach',\n",
       " '( my',\n",
       " '( networking',\n",
       " '( new',\n",
       " '( nutshell',\n",
       " \"( o'reilly\",\n",
       " '( office',\n",
       " '( official',\n",
       " '( oracle',\n",
       " '( osborne',\n",
       " '( outer',\n",
       " '( oxford',\n",
       " '( paperback',\n",
       " '( password',\n",
       " '( pattern-oriented',\n",
       " '( patterns',\n",
       " '( pdf',\n",
       " '( pearson',\n",
       " '( pocket',\n",
       " '( pragmatic',\n",
       " '( prentice',\n",
       " '( prentice-hall',\n",
       " '( princeton',\n",
       " '( pro',\n",
       " '( pro-developer',\n",
       " '( programmer',\n",
       " '( programming',\n",
       " '( progress',\n",
       " '( pts',\n",
       " '( python',\n",
       " '( quantitative',\n",
       " '( quick',\n",
       " '( quickbooks',\n",
       " '( quicken',\n",
       " '( r',\n",
       " '( raspberry',\n",
       " '( recipe',\n",
       " '( retro',\n",
       " '( saa-c',\n",
       " '( saas',\n",
       " '( sam',\n",
       " '( sams',\n",
       " '( sap',\n",
       " \"( schaum's\",\n",
       " '( scientific',\n",
       " '( scott',\n",
       " '( second',\n",
       " '( series',\n",
       " '( shelly',\n",
       " '( shortcut',\n",
       " '( signals',\n",
       " '( sigs',\n",
       " '( simplified',\n",
       " '( skills',\n",
       " '( spanish',\n",
       " '( springer',\n",
       " '( springerbriefs',\n",
       " '( sql',\n",
       " '( standalone',\n",
       " '( statistics',\n",
       " '( stay',\n",
       " '( step',\n",
       " '( step-by-step',\n",
       " '( student',\n",
       " '( studies',\n",
       " '( synthesis',\n",
       " '( systems',\n",
       " '( teach',\n",
       " '( tech',\n",
       " '( technology',\n",
       " '( texts',\n",
       " '( the',\n",
       " '( theory',\n",
       " '( third',\n",
       " '( tm',\n",
       " '( undergraduate',\n",
       " '( universitext',\n",
       " '( unofficial',\n",
       " '( use',\n",
       " '( using',\n",
       " '( v',\n",
       " '( version',\n",
       " '( visual',\n",
       " '( voices',\n",
       " '( vol',\n",
       " '( volume',\n",
       " \"( what's\",\n",
       " '( wiley',\n",
       " '( wireless',\n",
       " '( with',\n",
       " '( woodhead',\n",
       " '( wordware',\n",
       " '( world',\n",
       " '( your',\n",
       " '( zed',\n",
       " '(8',\n",
       " '(8 th',\n",
       " ')',\n",
       " ') (',\n",
       " ') )',\n",
       " ') ,',\n",
       " ') -',\n",
       " ') .',\n",
       " ') 2',\n",
       " ') and',\n",
       " ') book',\n",
       " ') by',\n",
       " ') cert',\n",
       " ') certification',\n",
       " ') essentials',\n",
       " ') exam',\n",
       " ') for',\n",
       " ') fuck',\n",
       " ') guide',\n",
       " ') hardcover',\n",
       " ') paperback',\n",
       " ') printed',\n",
       " ') user',\n",
       " ') with',\n",
       " ') |',\n",
       " '):',\n",
       " '): a',\n",
       " '): an',\n",
       " '): autodesk',\n",
       " '): covers',\n",
       " '): exam',\n",
       " '): keep',\n",
       " '): learn',\n",
       " '): the',\n",
       " ');',\n",
       " '*',\n",
       " '* plus',\n",
       " '+',\n",
       " '+ (',\n",
       " '+ +',\n",
       " '+ ,',\n",
       " '+ /',\n",
       " '+ 17',\n",
       " '+ 20',\n",
       " '+ :',\n",
       " '+ all-in-one',\n",
       " '+ and',\n",
       " '+ application',\n",
       " '+ book',\n",
       " '+ by',\n",
       " '+ certification',\n",
       " '+ complete',\n",
       " '+ cookbook',\n",
       " '+ core',\n",
       " '+ cybersecurity',\n",
       " '+ data',\n",
       " '+ dvd',\n",
       " '+ exam',\n",
       " '+ for',\n",
       " '+ from',\n",
       " '+ game',\n",
       " '+ gui',\n",
       " '+ guide',\n",
       " '+ high',\n",
       " '+ how',\n",
       " '+ keyboarding',\n",
       " '+ libraries',\n",
       " '+ lms',\n",
       " '+ mindtap',\n",
       " '+ multithreading',\n",
       " '+ mylab',\n",
       " '+ n10',\n",
       " '+ network',\n",
       " '+ pages',\n",
       " '+ plus',\n",
       " '+ practice',\n",
       " '+ programming',\n",
       " '+ reactive',\n",
       " '+ sam',\n",
       " '+ simple',\n",
       " '+ sql',\n",
       " '+ standard',\n",
       " '+ study',\n",
       " '+ sy0',\n",
       " '+ the',\n",
       " '+ tips',\n",
       " '+ windows',\n",
       " '+ with',\n",
       " ',',\n",
       " ', &',\n",
       " ', (',\n",
       " ', ...',\n",
       " ', 1',\n",
       " ', 100',\n",
       " ', 10th',\n",
       " ', 11',\n",
       " ', 110',\n",
       " ', 125',\n",
       " ', 130',\n",
       " ', 1z0',\n",
       " ', 2',\n",
       " ', 2000',\n",
       " ', 2001',\n",
       " ', 2002',\n",
       " ', 2003',\n",
       " ', 2004',\n",
       " ', 2005',\n",
       " ', 2006',\n",
       " ', 2007',\n",
       " ', 2008',\n",
       " ', 2009',\n",
       " ', 2010',\n",
       " ', 2011',\n",
       " ', 2012',\n",
       " ', 2013',\n",
       " ', 2014',\n",
       " ', 2015',\n",
       " ', 2016',\n",
       " ', 2017',\n",
       " ', 2018',\n",
       " ', 2019',\n",
       " ', 20th',\n",
       " ', 2nd',\n",
       " ', 3-5',\n",
       " ', 3d',\n",
       " ', 3e',\n",
       " ', 3rd',\n",
       " ', 4',\n",
       " ', 4th',\n",
       " ', 5',\n",
       " ', 5.5',\n",
       " ', 5th',\n",
       " ', 6',\n",
       " ', 6th',\n",
       " ', 6x9',\n",
       " ', 7th',\n",
       " ', 8.5',\n",
       " ', 8th',\n",
       " ', 9th',\n",
       " ', a',\n",
       " ', a20',\n",
       " ', access',\n",
       " ', accounting',\n",
       " ', administer',\n",
       " ', administration',\n",
       " ', agile',\n",
       " ', aiai',\n",
       " ', algorithms',\n",
       " ', alphabetical',\n",
       " ', amazon',\n",
       " ', an',\n",
       " ', analysis',\n",
       " ', analytics',\n",
       " ', analyzing',\n",
       " ', and',\n",
       " ', android',\n",
       " ', angular',\n",
       " ', apache',\n",
       " ', apis',\n",
       " ', applications',\n",
       " ', april',\n",
       " ', architecture',\n",
       " ', arduino',\n",
       " ', arm',\n",
       " ', artificial',\n",
       " ', assembly',\n",
       " ', attacks',\n",
       " ', august',\n",
       " ', authentication',\n",
       " ', automate',\n",
       " ', autonomous',\n",
       " ', backups',\n",
       " ', barcelona',\n",
       " ', basic',\n",
       " \", beginner's\",\n",
       " ', beginners',\n",
       " ', behavioral-cultural',\n",
       " ', best',\n",
       " ', big',\n",
       " ', bilbao',\n",
       " ', bitcoin',\n",
       " ', blockchain',\n",
       " ', book',\n",
       " ', bookkeeping',\n",
       " ', boost',\n",
       " ', bootstrap',\n",
       " ', both',\n",
       " ', brief',\n",
       " ', build',\n",
       " ', building',\n",
       " ', buildings',\n",
       " ', business',\n",
       " ', c',\n",
       " ', ca',\n",
       " ', canada',\n",
       " ', cc',\n",
       " ', certificates',\n",
       " ', challenges',\n",
       " ', charts',\n",
       " ', china',\n",
       " ', circuits',\n",
       " ', coding',\n",
       " ', collaboration',\n",
       " ', college',\n",
       " ', compilers',\n",
       " ', complete',\n",
       " ', comprehensive',\n",
       " ', computer',\n",
       " ', computers',\n",
       " ', concepts',\n",
       " ', concurrency',\n",
       " ', concurrent',\n",
       " ', configure',\n",
       " ', configuring',\n",
       " ', consistency',\n",
       " ', control',\n",
       " ', cpas',\n",
       " ', cryptography',\n",
       " ', css',\n",
       " ', customize',\n",
       " ', cybersecurity',\n",
       " ', data',\n",
       " ', database',\n",
       " ', debugging',\n",
       " ', december',\n",
       " ', decision',\n",
       " ', deploy',\n",
       " ', deploying',\n",
       " ', deployment',\n",
       " ', design',\n",
       " ', designers',\n",
       " ', developing',\n",
       " ', development',\n",
       " ', devops',\n",
       " ', diary',\n",
       " ', digital',\n",
       " ', docker',\n",
       " ', docs',\n",
       " ', document',\n",
       " ', dot',\n",
       " ', dot-to-dot',\n",
       " ', early',\n",
       " ', easy',\n",
       " ', ecmda-fa',\n",
       " ', editing',\n",
       " ', effective',\n",
       " ', efficient',\n",
       " ', eighth',\n",
       " ', emails',\n",
       " ', engineering',\n",
       " ', ethical',\n",
       " ', even',\n",
       " ', exam',\n",
       " ', excel',\n",
       " ', express',\n",
       " ', fast',\n",
       " ', fc',\n",
       " ', february',\n",
       " ', fifth',\n",
       " ', first',\n",
       " ', for',\n",
       " ', forensic',\n",
       " ', formatting',\n",
       " ', fourth',\n",
       " ', france',\n",
       " ', from',\n",
       " ', functions',\n",
       " ', games',\n",
       " ', gatk',\n",
       " ', germany',\n",
       " ', get',\n",
       " ', gift',\n",
       " ', github',\n",
       " ', google',\n",
       " ', governance',\n",
       " ', greece',\n",
       " ', hackers',\n",
       " ', hacking',\n",
       " ', healthy',\n",
       " ', held',\n",
       " ', hidden',\n",
       " ', high',\n",
       " ', hipeac',\n",
       " ', home',\n",
       " ', homeschool',\n",
       " ', how',\n",
       " ', html',\n",
       " ', hyperledger',\n",
       " ', iaas',\n",
       " ', icsi',\n",
       " ', ifl',\n",
       " ', illustrated',\n",
       " ', image',\n",
       " ', implementation',\n",
       " ', in',\n",
       " ', including',\n",
       " ', increase',\n",
       " ', instagram',\n",
       " ', installation',\n",
       " ', interactive',\n",
       " ', interfacing',\n",
       " ', intermediate',\n",
       " ', intermediates',\n",
       " ', internet',\n",
       " ', introductory',\n",
       " ', investigation',\n",
       " ', iot',\n",
       " ', italy',\n",
       " ', japan',\n",
       " ', java',\n",
       " ', javascript',\n",
       " ', jquery',\n",
       " ', json',\n",
       " ', july',\n",
       " ', june',\n",
       " ', kali',\n",
       " ', keras',\n",
       " ', keynote',\n",
       " ', kindergartens',\n",
       " ', kubernetes',\n",
       " ', languages',\n",
       " ', large',\n",
       " ', lcpc',\n",
       " ', lean',\n",
       " ', learning',\n",
       " ', lessons',\n",
       " ', linkedin',\n",
       " ', linux',\n",
       " ', live',\n",
       " ', log',\n",
       " ', logic',\n",
       " ', login',\n",
       " ', loose-leaf',\n",
       " ', los',\n",
       " ', lose',\n",
       " ', low',\n",
       " ', lunch',\n",
       " ', mac',\n",
       " ', machine',\n",
       " ', machines',\n",
       " ', maintain',\n",
       " ', maintainable',\n",
       " ', maintaining',\n",
       " ', maintenance',\n",
       " ', making',\n",
       " ', malware',\n",
       " ', manage',\n",
       " ', managing',\n",
       " ', march',\n",
       " ', materials',\n",
       " ', math',\n",
       " ', matte',\n",
       " ', may',\n",
       " ', mazes',\n",
       " ', meetings',\n",
       " ', memory',\n",
       " ', methods',\n",
       " ', microsoft',\n",
       " ', mobile',\n",
       " ', models',\n",
       " ', monitor',\n",
       " ', monitoring',\n",
       " ', music',\n",
       " ', mysql',\n",
       " ', network',\n",
       " ', networking',\n",
       " ', new',\n",
       " ', ninth',\n",
       " ', no',\n",
       " ', nosql',\n",
       " ', notebook',\n",
       " ', november',\n",
       " ', numpy',\n",
       " ', nursery',\n",
       " ', october',\n",
       " ', office',\n",
       " ', one',\n",
       " ', online',\n",
       " ', opencv',\n",
       " ', operating',\n",
       " ', or',\n",
       " ', oracle',\n",
       " ', organizer',\n",
       " ', pa',\n",
       " ', paas',\n",
       " ', pandas',\n",
       " ', part',\n",
       " ', parts',\n",
       " ', password',\n",
       " ', passwords',\n",
       " ', patterns',\n",
       " ', penetration',\n",
       " ', performance',\n",
       " ', photos',\n",
       " ', php',\n",
       " ', plan',\n",
       " ', planning',\n",
       " ', plus',\n",
       " ', portugal',\n",
       " ', power',\n",
       " ', powerpoint',\n",
       " ', powershell',\n",
       " ', practical',\n",
       " ', practice',\n",
       " ', practices',\n",
       " ', predictive',\n",
       " ', premium',\n",
       " ', principles',\n",
       " ', printed',\n",
       " ', printing',\n",
       " ', privacy',\n",
       " ', pro',\n",
       " ', proadvisors',\n",
       " ', proceedings',\n",
       " ', processes',\n",
       " ', processing',\n",
       " ', program',\n",
       " ', programming',\n",
       " ', protocols',\n",
       " ', puzzles',\n",
       " ', python',\n",
       " ', quantum',\n",
       " ', quick',\n",
       " ', quickbooks',\n",
       " ', r',\n",
       " ', raspberry',\n",
       " ', razor',\n",
       " ', react',\n",
       " ', real-time',\n",
       " ', real-world',\n",
       " ', reduce',\n",
       " ', reflection',\n",
       " ', reliable',\n",
       " ', remote',\n",
       " ', reporting',\n",
       " ', reports',\n",
       " ', reversing',\n",
       " ', revised',\n",
       " ', robotics',\n",
       " ', sales',\n",
       " ', sams',\n",
       " ', save',\n",
       " ', sbp',\n",
       " ', scada',\n",
       " ', scalability',\n",
       " ', scalable',\n",
       " ', scaling',\n",
       " ', science',\n",
       " ', scikit-learn',\n",
       " ', scipy',\n",
       " ', scripting',\n",
       " ', scrum',\n",
       " ', searching',\n",
       " ', second',\n",
       " ', secure',\n",
       " ', security',\n",
       " ', seniors',\n",
       " ', sensors',\n",
       " ', september',\n",
       " ', serial',\n",
       " ', services',\n",
       " ', set',\n",
       " ', seventh',\n",
       " ', share',\n",
       " ', sheets',\n",
       " ', shortcuts',\n",
       " ', simulation',\n",
       " ', sixth',\n",
       " ', small',\n",
       " ', smart',\n",
       " ', soap',\n",
       " ', social',\n",
       " ', soft',\n",
       " ', software',\n",
       " ', sorting',\n",
       " ', spain',\n",
       " ', special',\n",
       " ', spiral',\n",
       " ', spring',\n",
       " ', sql',\n",
       " ', standards',\n",
       " ', statistics',\n",
       " ', step',\n",
       " ', step-by-step',\n",
       " ', storage',\n",
       " ', strategies',\n",
       " ', streaming',\n",
       " ', streams',\n",
       " ', student',\n",
       " ', surveillance',\n",
       " ', sweden',\n",
       " ', switzerland',\n",
       " ', systems',\n",
       " ', techniques',\n",
       " ', technologies',\n",
       " ', technology',\n",
       " ', tenth',\n",
       " ', test',\n",
       " ', testing',\n",
       " ', the',\n",
       " ', theory',\n",
       " ', third',\n",
       " ', time',\n",
       " ', tips',\n",
       " ', to',\n",
       " ', toddlers',\n",
       " ', tools',\n",
       " ', training',\n",
       " ', trainings',\n",
       " ', tricks',\n",
       " ', troubleshoot',\n",
       " ', troubleshooting',\n",
       " ', tuning',\n",
       " ', tutorials',\n",
       " ', twitter',\n",
       " ', uk',\n",
       " ', unix',\n",
       " ', updated',\n",
       " ', usa',\n",
       " ', use',\n",
       " ', username',\n",
       " ', usernames',\n",
       " ', using',\n",
       " ', version',\n",
       " ', video',\n",
       " ', virtualization',\n",
       " ', visualization',\n",
       " ', visualizing',\n",
       " ', vol',\n",
       " ', volume',\n",
       " ', web',\n",
       " ', website',\n",
       " ', windows',\n",
       " ', wireless',\n",
       " ', with',\n",
       " ', women',\n",
       " ', word',\n",
       " ', work',\n",
       " ', writing',\n",
       " ', xhtml',\n",
       " ', xml',\n",
       " ', xpath',\n",
       " ', xslt',\n",
       " ', your',\n",
       " '-',\n",
       " '- -',\n",
       " '- 001',\n",
       " '- 002',\n",
       " '- 005',\n",
       " '- 006',\n",
       " '- 007',\n",
       " '- 051',\n",
       " '- 061',\n",
       " '- 062',\n",
       " '- 063',\n",
       " '- 1',\n",
       " '- 100',\n",
       " '- 101',\n",
       " '- 103',\n",
       " '- 11',\n",
       " '- 120',\n",
       " '- 2',\n",
       " '- 201',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokens.vocabulary_\n",
    "#지난번 프로젝트에서 생성하던 토큰 방식임\n",
    "tokens.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "워드 벡터에 어휘를 추가하기 위한 코드\n",
    "아마존 데이터 추가\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = []\n",
    "for token in Adata['title']:\n",
    "    tokens.append(tokenizer.tokenize(token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드벡터에 Orelly 데이터 추가\n",
    "Odata = pd.read_excel('Oreilly_IT_Book.xlsx')\n",
    "for token in Odata['title']:\n",
    "    tokens.append(tokenizer.tokenize(token))\n",
    "    \n",
    "for token in Odata['description']:\n",
    "    tokens.append(tokenizer.tokenize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드 벡터에 Packt의 Description 추가\n",
    "Pdata = pd.read_excel('Packt.xlsx')\n",
    "for token in Pdata['title']:\n",
    "    tokens.append(tokenizer.tokenize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드 벡터에 추가적으로 크롤링한 Amazon 데이터 추가\n",
    "Amdata = pd.read_excel('Amazon.xlsx')\n",
    "for token in Odata['title']:\n",
    "    tokens.append(tokenizer.tokenize(token))\n",
    "    \n",
    "for token in Odata['description']:\n",
    "    tokens.append(tokenizer.tokenize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드 벡터 생성\n",
    "\n",
    "num_features = 300 # 단어 벡터 차원수\n",
    "min_word_count = 3 # 지난 토큰 생성기와 동일하게 min_df =3 으로 입력\n",
    "window_size=5   # 워드 벡터의 문맥을 파악하는 길이 (특정 단어가 들어갈 위치의 양 옆으로 window_size만큼의 단어들로 들어갈 단어 예측)\n",
    "subsampling =1e-4  #많은 양의 토큰이 있을경우 처리 (빈도수가 많이 나오는 단어는 학습량을 의도적으로 줄일때 사용하는 매개변수)\n",
    "\n",
    "word_vector = Word2Vec(tokens, size=num_features, min_count=min_word_count,window=window_size,sample=subsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#생성한 워드 벡터 저장하는 코드\n",
    "\n",
    "model_name = \"p15_word2vec_3\"\n",
    "word_vector.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p15_word2vec_2 19:29 Orelly data 추가한 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('learning', 0.8743589520454407),\n",
       " ('web', 0.8708198070526123),\n",
       " ('machine', 0.8542468547821045),\n",
       " ('applications', 0.8517473936080933),\n",
       " ('analysis', 0.8435206413269043),\n",
       " ('problems', 0.8325647115707397),\n",
       " ('modern', 0.8236908912658691),\n",
       " ('algorithms', 0.8201415538787842),\n",
       " ('models', 0.8180030584335327),\n",
       " ('development', 0.8131026029586792)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 불러올때\n",
    "model_name = \"p15_word2vec_3\"\n",
    "word_vector = Word2Vec.load(model_name)\n",
    "word_vector.most_similar('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenizer.tokenize(sample)\n",
    "        sample_vecs = []\n",
    "        \"\"\"\n",
    "        it 도서 분류를 위해 만든 word2벡터를 불러옴\n",
    "        워드 벡터에 없는 단어는 분류에 필요없는 토큰으로 여기고 제거\n",
    "        \"\"\"\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vector[token])\n",
    "                \n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "        vectorized_data.append(sample_vecs)\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 훈련용 데이터의 단어 길이를 맞추기 위한 함수\n",
    "def pad(data, maxlen):\n",
    "    new_data = []\n",
    "    \n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "        \n",
    "    for sample in data:\n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            \n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 지난번 프로젝트와 동일한 데이터를 훈련용과 테스트용으로 나눔\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = tokenize_and_vectorize(Adata['title'])\n",
    "y = Adata['theme']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 데이터를 CNN모델에 학습 시킬 자료를 3차원 벡터로 변환\n",
    "X_train = pad(X_train, maxlen)\n",
    "X_train = np.reshape(X_train, (len(X_train), maxlen, embedding_dims))\n",
    "\n",
    "X_test = pad(X_test, maxlen)\n",
    "X_test = np.reshape(X_test, (len(X_test), maxlen, embedding_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IoT&Hardware', 'Security', 'Cloud&Networking', 'Data',\n",
       "       'Business&Other', 'Programming', 'WebDevelopment', 'Mobile',\n",
       "       'Game Development'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = y_train.unique() # 라벨로 사용할 9개의 값 따로 저장\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영문으로 된 라벨을 훈련용으로 변환하기 위해 숫자 0~8로 바꾸는 함수\n",
    "\n",
    "\n",
    "def labeling(data):\n",
    "    y_train_shape = []\n",
    "    \n",
    "    for label in data:\n",
    "        for i in range(0,9):\n",
    "            if label_list[i] == label :\n",
    "                y_train_shape.append(i)\n",
    "                \n",
    "    return y_train_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영문으로 된 라벨을 숫자(0~8)로 바꿈\n",
    "\n",
    "y_train = labeling(y_train)\n",
    "y_test = labeling(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨 데이터를 원핫 인코딩을 통해 훈련용으로 변환\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = np.array(y_train)\n",
    "y_train_cat = to_categorical(y_train, 9)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "y_test_cat = to_categorical(y_test, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15908, 9)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10 # 각 훈련데이터당 토큰의 최대 개수\n",
    "batch_size = 20 # 역전파 하기까지 처리해야하는 데이터수\n",
    "embedding_dims = 300  #토큰 벡터의 길이(차원수)\n",
    "filters = 250    #훈련에 사용할 필터 개수\n",
    "kernel_size = 2 #1차원 필터의 너비\n",
    "hidden_dims = 250 #은닉층 개수\n",
    "epochs = 12 #훈련 반복 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#활성화 함수는 relu 사용, 토큰 벡터의 길이는 워드 벡터와 마찬가지로 300으로 맞춤\n",
    "# feature map의 남는 공간을 채울 수 있도록 padding 활성화, stride는 띄어넘는 단어가 없도록 1로 설정\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(\n",
    "filters, kernel_size, padding='valid', activation='relu', strides=1, input_shape=(maxlen, embedding_dims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling 활성화\n",
    "model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 과정중 과대적합을 피하기 위해 드롭아웃을 사용\n",
    "#20% 데이터가 훈련 과정중 무작위로 폐기됨\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#출력층은 라벨 수에 맞쳐 9개로 입력\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수로 분류명이 여러개일때 사용하는 categorical_crossentropy 사용하여 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15908 samples, validate on 2808 samples\n",
      "Epoch 1/12\n",
      "15908/15908 [==============================] - 20s 1ms/step - loss: 1.6561 - accuracy: 0.3597 - val_loss: 1.4474 - val_accuracy: 0.4580\n",
      "Epoch 2/12\n",
      "15908/15908 [==============================] - 19s 1ms/step - loss: 1.3681 - accuracy: 0.5051 - val_loss: 1.3216 - val_accuracy: 0.5078\n",
      "Epoch 3/12\n",
      "15908/15908 [==============================] - 20s 1ms/step - loss: 1.2527 - accuracy: 0.5519 - val_loss: 1.3179 - val_accuracy: 0.5377\n",
      "Epoch 4/12\n",
      "15908/15908 [==============================] - 19s 1ms/step - loss: 1.1731 - accuracy: 0.5813 - val_loss: 1.2507 - val_accuracy: 0.5566\n",
      "Epoch 5/12\n",
      "15908/15908 [==============================] - 20s 1ms/step - loss: 1.1166 - accuracy: 0.6032 - val_loss: 1.2063 - val_accuracy: 0.5673\n",
      "Epoch 6/12\n",
      "15908/15908 [==============================] - 26s 2ms/step - loss: 1.0636 - accuracy: 0.6143 - val_loss: 1.1948 - val_accuracy: 0.5826\n",
      "Epoch 7/12\n",
      "15908/15908 [==============================] - 22s 1ms/step - loss: 1.0233 - accuracy: 0.6312 - val_loss: 1.2161 - val_accuracy: 0.5719\n",
      "Epoch 8/12\n",
      "15908/15908 [==============================] - 23s 1ms/step - loss: 0.9817 - accuracy: 0.6479 - val_loss: 1.1931 - val_accuracy: 0.5848\n",
      "Epoch 9/12\n",
      "15908/15908 [==============================] - 22s 1ms/step - loss: 0.9416 - accuracy: 0.6547 - val_loss: 1.2067 - val_accuracy: 0.5912\n",
      "Epoch 10/12\n",
      "15908/15908 [==============================] - 20s 1ms/step - loss: 0.9166 - accuracy: 0.6621 - val_loss: 1.2689 - val_accuracy: 0.5545\n",
      "Epoch 11/12\n",
      "15908/15908 [==============================] - 20s 1ms/step - loss: 0.8791 - accuracy: 0.6749 - val_loss: 1.2315 - val_accuracy: 0.5762\n",
      "Epoch 12/12\n",
      "15908/15908 [==============================] - 24s 2ms/step - loss: 0.8542 - accuracy: 0.6854 - val_loss: 1.2438 - val_accuracy: 0.5830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17ae5a299e8>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "이번 프로젝트에서는 책 제목 특성상 카테고리가 겹치는 경우가 많으므로 테스트 셋의 예측결과를 평가지표로 사용하지 않고\n",
    "최고 정확도와 유사한 예측값들은 함께 다중라벨링 처리를 할 수 있는지를 모델의 성능 평가 지표로 활용함\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#만든 모델 저장\n",
    "model.save('nlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#만든 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model2 = load_model('nlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련에 사용하지 않은 베스트 셀러 데이터 불러옴\n",
    "pro = pd.read_csv('prog_book.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Book_title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number_Of_Pages</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.17</td>\n",
       "      <td>3,829</td>\n",
       "      <td>The Elements of Style</td>\n",
       "      <td>This style manual offers practical advice on i...</td>\n",
       "      <td>105</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.01</td>\n",
       "      <td>1,406</td>\n",
       "      <td>The Information: A History, a Theory, a Flood</td>\n",
       "      <td>James Gleick, the author of the best sellers C...</td>\n",
       "      <td>527</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.33</td>\n",
       "      <td>0</td>\n",
       "      <td>Responsive Web Design Overview For Beginners</td>\n",
       "      <td>In Responsive Web Design Overview For Beginner...</td>\n",
       "      <td>50</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>11.267647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.97</td>\n",
       "      <td>1,658</td>\n",
       "      <td>Ghost in the Wires: My Adventures as the World...</td>\n",
       "      <td>If they were a hall of fame or shame for compu...</td>\n",
       "      <td>393</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>12.873529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.06</td>\n",
       "      <td>1,325</td>\n",
       "      <td>How Google Works</td>\n",
       "      <td>Both Eric Schmidt and Jonathan Rosenberg came ...</td>\n",
       "      <td>305</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>13.164706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating Reviews                                         Book_title  \\\n",
       "0    4.17   3,829                              The Elements of Style   \n",
       "1    4.01   1,406      The Information: A History, a Theory, a Flood   \n",
       "2    3.33       0       Responsive Web Design Overview For Beginners   \n",
       "3    3.97   1,658  Ghost in the Wires: My Adventures as the World...   \n",
       "4    4.06   1,325                                   How Google Works   \n",
       "\n",
       "                                         Description  Number_Of_Pages  \\\n",
       "0  This style manual offers practical advice on i...              105   \n",
       "1  James Gleick, the author of the best sellers C...              527   \n",
       "2  In Responsive Web Design Overview For Beginner...               50   \n",
       "3  If they were a hall of fame or shame for compu...              393   \n",
       "4  Both Eric Schmidt and Jonathan Rosenberg came ...              305   \n",
       "\n",
       "             Type      Price  \n",
       "0       Hardcover   9.323529  \n",
       "1       Hardcover  11.000000  \n",
       "2  Kindle Edition  11.267647  \n",
       "3       Hardcover  12.873529  \n",
       "4  Kindle Edition  13.164706  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test = tokenize_and_vectorize(pro['Book_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = pad(test, maxlen)\n",
    "test_train = np.reshape(test_train, (len(test_train), maxlen, embedding_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre =model2.predict(test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최고치랑 비슷한 예측값들은 다중 라벨링 처리\n",
    "def multi_label(data):\n",
    "    count = []\n",
    "    for i in range(0, len(data)):\n",
    "        best = 0\n",
    "        co = []\n",
    "\n",
    "        for j in range(0,9):\n",
    "        \n",
    "            if pre[i][j]> best :\n",
    "                best = data[i][j]\n",
    "        for j in range(0,9):\n",
    "        \n",
    "            if pre[i][j] > best*0.9:\n",
    "                co.append(j)\n",
    "        count.append(co)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#숫자로 된 라벨을 다시 영문으로 바꾸는 함수\n",
    "\n",
    "\n",
    "def labeling_c(data):\n",
    "    str_label = []\n",
    "    for label in data:\n",
    "        sub_str = []\n",
    "        print(label)\n",
    "        for i in range(0,len(label)):\n",
    "            for j in range(0,9):\n",
    "                \n",
    "                if j == label[i] :\n",
    "                    sub_str.append(label_list[j])\n",
    "        str_label.append(sub_str)      \n",
    "    return str_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[4]\n",
      "[1]\n",
      "[3, 6]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[2]\n",
      "[7]\n",
      "[2, 4]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[1]\n",
      "[4]\n",
      "[7]\n",
      "[8]\n",
      "[4]\n",
      "[7]\n",
      "[1]\n",
      "[4]\n",
      "[7]\n",
      "[6]\n",
      "[3]\n",
      "[7]\n",
      "[4]\n",
      "[4]\n",
      "[7]\n",
      "[4]\n",
      "[4]\n",
      "[4, 7]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[1]\n",
      "[7]\n",
      "[3]\n",
      "[3]\n",
      "[7]\n",
      "[4]\n",
      "[4, 6]\n",
      "[3, 4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[7]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[1, 6]\n",
      "[3]\n",
      "[8]\n",
      "[1]\n",
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[8]\n",
      "[4]\n",
      "[1]\n",
      "[7]\n",
      "[7]\n",
      "[3]\n",
      "[6]\n",
      "[6]\n",
      "[8]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[2]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[1]\n",
      "[4]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[1]\n",
      "[1]\n",
      "[6]\n",
      "[4]\n",
      "[3]\n",
      "[6]\n",
      "[4]\n",
      "[1]\n",
      "[1]\n",
      "[4]\n",
      "[4]\n",
      "[3, 4]\n",
      "[4]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[8]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3, 4]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[8]\n",
      "[8]\n",
      "[3, 4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[8]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[8]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[8]\n",
      "[4]\n",
      "[1, 4]\n",
      "[4, 6]\n",
      "[3]\n",
      "[3]\n",
      "[2, 4]\n",
      "[3]\n",
      "[1, 3]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[8]\n",
      "[4]\n",
      "[8]\n",
      "[8]\n",
      "[3, 8]\n",
      "[1, 2]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[8]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[8]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[1, 4]\n",
      "[8]\n",
      "[3]\n",
      "[4]\n",
      "[8]\n",
      "[8]\n",
      "[4]\n",
      "[8]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Cloud&Networking'],\n",
       " ['Security'],\n",
       " ['Data'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Security'],\n",
       " ['Data', 'WebDevelopment'],\n",
       " ['Business&Other'],\n",
       " ['Cloud&Networking'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Cloud&Networking'],\n",
       " ['Mobile'],\n",
       " ['Cloud&Networking', 'Business&Other'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Cloud&Networking'],\n",
       " ['IoT&Hardware'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Mobile'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Mobile'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Mobile'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Mobile'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Mobile'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other', 'Mobile'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Security'],\n",
       " ['Mobile'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Mobile'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other', 'WebDevelopment'],\n",
       " ['Data', 'Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Mobile'],\n",
       " ['Cloud&Networking'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Security', 'WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Game Development'],\n",
       " ['Security'],\n",
       " ['Cloud&Networking'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Security'],\n",
       " ['Mobile'],\n",
       " ['Mobile'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['WebDevelopment'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Cloud&Networking'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Cloud&Networking'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Security'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Security'],\n",
       " ['Security'],\n",
       " ['WebDevelopment'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Business&Other'],\n",
       " ['Security'],\n",
       " ['Security'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data', 'Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Game Development'],\n",
       " ['Cloud&Networking'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data', 'Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['IoT&Hardware'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Game Development'],\n",
       " ['Data', 'Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Game Development'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Game Development'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Security', 'Business&Other'],\n",
       " ['Business&Other', 'WebDevelopment'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Cloud&Networking', 'Business&Other'],\n",
       " ['Data'],\n",
       " ['Security', 'Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Game Development'],\n",
       " ['Data', 'Game Development'],\n",
       " ['Security', 'Cloud&Networking'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['WebDevelopment'],\n",
       " ['Game Development'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['WebDevelopment'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Security', 'Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Data'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Game Development'],\n",
       " ['Business&Other'],\n",
       " ['Game Development'],\n",
       " ['Security'],\n",
       " ['Data'],\n",
       " ['Data'],\n",
       " ['Business&Other']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling_c(multi_label(pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = pro['Book_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[7]\n",
      "[2, 3]\n",
      "[7]\n",
      "[2]\n",
      "[7]\n",
      "[2]\n",
      "[4]\n",
      "[2]\n",
      "[8]\n",
      "[4]\n",
      "[7]\n",
      "[2, 6]\n",
      "[4]\n",
      "[2, 7]\n",
      "[2, 7]\n",
      "[4]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[1]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[1]\n",
      "[2]\n",
      "[7]\n",
      "[4]\n",
      "[7]\n",
      "[8]\n",
      "[3]\n",
      "[7]\n",
      "[4]\n",
      "[6]\n",
      "[7]\n",
      "[1]\n",
      "[4]\n",
      "[1, 7]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[6]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[4]\n",
      "[3]\n",
      "[8]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[1]\n",
      "[6]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[6]\n",
      "[7]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[4, 7]\n",
      "[2, 4]\n",
      "[3]\n",
      "[8]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[8]\n",
      "[6]\n",
      "[1]\n",
      "[2, 3]\n",
      "[7]\n",
      "[3]\n",
      "[2]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[7]\n",
      "[2]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[1]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[7]\n",
      "[3]\n",
      "[1]\n",
      "[4]\n",
      "[3]\n",
      "[1]\n",
      "[4]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[1]\n",
      "[1, 5]\n",
      "[6]\n",
      "[7]\n",
      "[4]\n",
      "[6]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[7]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[6]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[8]\n",
      "[1]\n",
      "[7]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[7]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[4]\n",
      "[1, 3]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[1, 3, 6]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[8]\n",
      "[8]\n",
      "[1]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[8]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[2, 3]\n",
      "[3]\n",
      "[7]\n",
      "[3, 4]\n",
      "[1, 3]\n",
      "[3]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[8]\n",
      "[4]\n",
      "[4]\n",
      "[1]\n",
      "[4]\n",
      "[1]\n",
      "[6]\n",
      "[8]\n",
      "[4]\n",
      "[1]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[4]\n",
      "[3]\n",
      "[7]\n",
      "[3]\n",
      "[1]\n",
      "[3]\n",
      "[4]\n",
      "[1]\n",
      "[1]\n",
      "[2]\n",
      "[4]\n",
      "[6]\n",
      "[1]\n",
      "[8]\n",
      "[4]\n",
      "[8]\n",
      "[1, 2]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[8]\n",
      "[1, 6]\n",
      "[4]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[2]\n",
      "[1]\n",
      "[8]\n",
      "[4]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[8]\n",
      "[8]\n",
      "[3]\n",
      "[8]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "df['prediction'] = labeling_c(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('결과_2141.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = pd.read_csv('language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chicken is Right\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "lan_test = tokenize_and_vectorize(language['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_prediction = pad(lan_test, maxlen)\n",
    "lan_prediction = np.reshape(lan_prediction, (len(lan_prediction), maxlen, embedding_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lan =model2.predict(lan_prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lan = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lan['language'] = language['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1, 2, 3, 4, 6, 7]\n",
      "[]\n",
      "[]\n",
      "[1, 2, 3, 4, 6, 7]\n",
      "[3]\n",
      "[]\n",
      "[]\n",
      "[1]\n",
      "[3]\n",
      "[2, 4, 7]\n",
      "[]\n",
      "[4]\n",
      "[1, 2, 3, 4, 7]\n",
      "[1, 2, 3, 4, 6, 7]\n",
      "[2, 7]\n",
      "[2]\n",
      "[1, 6]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "word2vec에서 아직 프로그래밍 언어의 학습이 부족함\n",
    "아직 워드 투 벡터 구축에 사용된 데이터의 양이 부족해 발생한 문제로 추정되어\n",
    "데이터의 양을 늘려야될 것 같음\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_lan['predictiobn'] = labeling_c(multi_label(pre_lan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lan.to_excel('언어와 관련된 기술.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_excel('결과_2141.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Programming']                              84\n",
       "['IoT&Hardware']                             46\n",
       "['Data']                                     43\n",
       "['Business&Other']                           25\n",
       "['Security']                                 23\n",
       "['Game Development']                         19\n",
       "['Cloud&Networking']                         14\n",
       "['Cloud&Networking', 'Programming']           3\n",
       "['Cloud&Networking', 'Security']              2\n",
       "['Data', 'Programming']                       2\n",
       "['Data', 'Security']                          1\n",
       "['Data', 'WebDevelopment']                    1\n",
       "['IoT&Hardware', 'Security']                  1\n",
       "['Mobile']                                    1\n",
       "['Data', 'Programming', 'Business&Other']     1\n",
       "['Programming', 'IoT&Hardware']               1\n",
       "['Data', 'Cloud&Networking']                  1\n",
       "['Data', 'Business&Other']                    1\n",
       "['Cloud&Networking', 'Business&Other']        1\n",
       "['Cloud&Networking', 'IoT&Hardware']          1\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "딥러닝 프로젝트 평가:\n",
    "지난 프로젝트로 만든 단어 빈도수에 의존하는 자연어 처리 모델에 비해 다중 라벨링이나 \n",
    "책의 제목을 카테고리에 맞게 분류하는 성능이 향상되었음을 확인할 수 있었음\n",
    "아직 분류 성능이 만족스러운 정도는 아니지만 프로젝트의 목표인 딥러닝을 통해 성능 개선이 이루어진다는 것을 확인해볼 수 있었음 \n",
    "앞으로 매개변수의 최적화나 word2vec의 어휘량 보강등 프로젝트 시간상 끝내지 못한 모델 최적화를 마무리하면\n",
    "모델 성능을 더욱 끌어올릴 수 있을 것이라고 기대됨\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
